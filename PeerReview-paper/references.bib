@Article{rs16050839,
    AUTHOR = {Sloan, Sean and Talkhani, Raiyan R. and Huang, Tao and Engert, Jayden and Laurance, William F.},
    TITLE = {Mapping Remote Roads Using Artificial Intelligence and Satellite Imagery},
    JOURNAL = {Remote Sensing},
    VOLUME = {16},
    YEAR = {2024},
    NUMBER = {5},
    ARTICLE-NUMBER = {839},
    URL = {https://www.mdpi.com/2072-4292/16/5/839},
    ISSN = {2072-4292},
    ABSTRACT = {Road building has long been under-mapped globally, arguably more than any other human activity threatening environmental integrity. Millions of kilometers of unmapped roads have challenged environmental governance and conservation in remote frontiers. Prior attempts to map roads at large scales have proven inefficient, incomplete, and unamenable to continuous road monitoring. Recent developments in automated road detection using artificial intelligence have been promising but have neglected the relatively irregular, sparse, rustic roadways characteristic of remote semi-natural areas. In response, we tested the accuracy of automated approaches to large-scale road mapping across remote rural and semi-forested areas of equatorial Asia-Pacific. Three machine learning models based on convolutional neural networks (UNet and two ResNet variants) were trained on road data derived from visual interpretations of freely available high-resolution satellite imagery. The models mapped roads with appreciable accuracies, with F1 scores of 72–81% and intersection over union scores of 43–58%. These results, as well as the purposeful simplicity and availability of our input data, support the possibility of concerted program of exhaustive, automated road mapping and monitoring across large, remote, tropical areas threatened by human encroachment.},
    DOI = {10.3390/rs16050839}
}

@article{JIN2005257,
title = {An integrated system for automatic road mapping from high-resolution multi-spectral satellite imagery by information fusion},
journal = {Information Fusion},
volume = {6},
number = {4},
pages = {257-273},
year = {2005},
note = {Fusion of Remotely Sensed Data over Urban Areas},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2004.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S1566253504000454},
author = {Xiaoying Jin and Curt H. Davis},
keywords = {Automatic road extraction, High-resolution satellite imagery, Perceptual grouping, Hypothesis and verification, Multi-detector fusion},
abstract = {Here we present an integrated system for automatic mapping of urban and suburban roads from high-resolution satellite imagery. Road extraction strategies can be enriched and improved by multi-source data fusion. Fusion can occur by combining road extraction results from different image sources, or by applying multiple detectors to a single source image and then fusing the multi-detector road extraction results. Our proposed system models roads differently for urban vs. suburban environments. In suburban areas, roads are modeled as curvilinear and homogeneous regions with nearly constant width. Roads are extracted by integrating the output of two road detectors followed by a road tracker. The first detector is based on fine-scale image segmentation and grouping where road centerlines are identified and extracted using shape and structure information from the segments. This detector generates a very reliable road extraction but is incomplete as many road segments are not captured. A multi-scale curvilinear structure detector based on differential geometry is used as a complementary detector. This detector utilizes a fuzzy decision algorithm based on a 1D road profile model. The final suburban road centerlines are generated by integrating the results from the two detectors using an optimum path search algorithm. In many dense urban areas in the US, road networks are composed primarily of straight lines that form a grid structure. Here we use directional morphological filtering to mask out dark and bright structures shorter than a city block. We then use a spatial signature weighted Hough transform to generate a road grid hypothesis. The modified Hough transform incorporates spatial information derived from surrounding image pixels and can be applied to multi-spectral images. Each piece of the hypothesized road grid is then verified using homogeneity, shape, and vegetation information from the local surrounding area. Missing pieces of the road network are added using a road tracker based on profile matching. The integrated road extraction system based on the fusion of multi-detector results is tested using IKONOS multi-spectral imagery of the City of Columbia, Missouri. Evaluation of the extracted road networks using representative test sites show completeness values that range between 70% and 86% and correctness values that range between 70% and 92%.}
}

@INPROCEEDINGS{10483606,
  author={Ren, Simiao and Luzi, Francesco and Lahrichi, Saad and Kassaw, Kaleb and Collins, Leslie M. and Bradbury, Kyle and Malof, Jordan M.},
  booktitle={2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={Segment anything, from space?}, 
  year={2024},
  volume={},
  number={},
  pages={8340-8350},
  keywords={Instance segmentation;Image segmentation;Systematics;Annotations;Target recognition;Roads;Benchmark testing;Applications;Remote Sensing;Algorithms;Image recognition and understanding},
  doi={10.1109/WACV57701.2024.00817}}

@Article{rs12091444,
AUTHOR = {Abdollahi, Arnick and Pradhan, Biswajeet and Shukla, Nagesh and Chakraborty, Subrata and Alamri, Abdullah},
TITLE = {Deep Learning Approaches Applied to Remote Sensing Datasets for Road Extraction: A State-Of-The-Art Review},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {1444},
URL = {https://www.mdpi.com/2072-4292/12/9/1444},
ISSN = {2072-4292},
ABSTRACT = {One of the most challenging research subjects in remote sensing is feature extraction, such as road features, from remote sensing images. Such an extraction influences multiple scenes, including map updating, traffic management, emergency tasks, road monitoring, and others. Therefore, a systematic review of deep learning techniques applied to common remote sensing benchmarks for road extraction is conducted in this study. The research is conducted based on four main types of deep learning methods, namely, the GANs model, deconvolutional networks, FCNs, and patch-based CNNs models. We also compare these various deep learning models applied to remote sensing datasets to show which method performs well in extracting road parts from high-resolution remote sensing images. Moreover, we describe future research directions and research gaps. Results indicate that the largest reported performance record is related to the deconvolutional nets applied to remote sensing images, and the F1 score metric of the generative adversarial network model, DenseNet method, and FCN-32 applied to UAV and Google Earth images are high: 96.08%, 95.72%, and 94.59%, respectively.},
DOI = {10.3390/rs12091444}
}

@INPROCEEDINGS{7729406,
  author={Zhong, Zilong and Li, Jonathan and Cui, Weihong and Jiang, Han},
  booktitle={2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)}, 
  title={Fully convolutional networks for building and road extraction: Preliminary results}, 
  year={2016},
  volume={},
  number={},
  pages={1591-1594},
  keywords={Roads;Buildings;Training;Image segmentation;Spatial resolution;Semantics;Computational modeling;Deep learning;fully convolutional networks;object extraction;high spatial resolution imagery},
  doi={10.1109/IGARSS.2016.7729406}}

@article{YUAN2021114417,
title = {A review of deep learning methods for semantic segmentation of remote sensing imagery},
journal = {Expert Systems with Applications},
volume = {169},
pages = {114417},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.114417},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420310836},
author = {Xiaohui Yuan and Jianfang Shi and Lichuan Gu},
keywords = {Semantic image segmentation, Deep neural networks, Remote sensing imagery},
abstract = {Semantic segmentation of remote sensing imagery has been employed in many applications and is a key research topic for decades. With the success of deep learning methods in the field of computer vision, researchers have made a great effort to transfer their superior performance to the field of remote sensing image analysis. This paper starts with a summary of the fundamental deep neural network architectures and reviews the most recent developments of deep learning methods for semantic segmentation of remote sensing imagery including non-conventional data such as hyperspectral images and point clouds. In our review of the literature, we identified three major challenges faced by researchers and summarize the innovative development to address them. As tremendous efforts have been devoted to advancing pixel-level accuracy, the emerged deep learning methods demonstrated much-improved performance on several public data sets. As to handling the non-conventional, unstructured point cloud and rich spectral imagery, the performance of the state-of-the-art methods is, on average, inferior to that of the satellite imagery. Such a performance gap also exists in learning from small data sets. In particular, the limited non-conventional remote sensing data sets with labels is an obstacle to developing and evaluating new deep learning methods.}
}


@Article{rs12101667,
AUTHOR = {Hoeser, Thorsten and Kuenzer, Claudia},
TITLE = {Object Detection and Image Segmentation with Deep Learning on Earth Observation Data: A Review-Part I: Evolution and Recent Trends},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {1667},
URL = {https://www.mdpi.com/2072-4292/12/10/1667},
ISSN = {2072-4292},
ABSTRACT = {Deep learning (DL) has great influence on large parts of science and increasingly established itself as an adaptive method for new challenges in the field of Earth observation (EO). Nevertheless, the entry barriers for EO researchers are high due to the dense and rapidly developing field mainly driven by advances in computer vision (CV). To lower the barriers for researchers in EO, this review gives an overview of the evolution of DL with a focus on image segmentation and object detection in convolutional neural networks (CNN). The survey starts in 2012, when a CNN set new standards in image recognition, and lasts until late 2019. Thereby, we highlight the connections between the most important CNN architectures and cornerstones coming from CV in order to alleviate the evaluation of modern DL models. Furthermore, we briefly outline the evolution of the most popular DL frameworks and provide a summary of datasets in EO. By discussing well performing DL architectures on these datasets as well as reflecting on advances made in CV and their impact on future research in EO, we narrow the gap between the reviewed, theoretical concepts from CV and practical application in EO.},
DOI = {10.3390/rs12101667}
}

@article{ALSHEHHI2017139,
title = {Simultaneous extraction of roads and buildings in remote sensing imagery with convolutional neural networks},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {130},
pages = {139-149},
year = {2017},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2017.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0924271617300096},
author = {Rasha Alshehhi and Prashanth Reddy Marpu and Wei Lee Woon and Mauro Dalla Mura},
keywords = {Convolutional neural network, Low-level features, Adjacent regions, Extraction},
abstract = {Extraction of man-made objects (e.g., roads and buildings) from remotely sensed imagery plays an important role in many urban applications (e.g., urban land use and land cover assessment, updating geographical databases, change detection, etc). This task is normally difficult due to complex data in the form of heterogeneous appearance with large intra-class and lower inter-class variations. In this work, we propose a single patch-based Convolutional Neural Network (CNN) architecture for extraction of roads and buildings from high-resolution remote sensing data. Low-level features of roads and buildings (e.g., asymmetry and compactness) of adjacent regions are integrated with Convolutional Neural Network (CNN) features during the post-processing stage to improve the performance. Experiments are conducted on two challenging datasets of high-resolution images to demonstrate the performance of the proposed network architecture and the results are compared with other patch-based network architectures. The results demonstrate the validity and superior performance of the proposed network architecture for extracting roads and buildings in urban areas.}
}

@Article{rs12182985,
AUTHOR = {Lin, Yeneng and Xu, Dongyun and Wang, Nan and Shi, Zhou and Chen, Qiuxiao},
TITLE = {Road Extraction from Very-High-Resolution Remote Sensing Images via a Nested SE-Deeplab Model},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {2985},
URL = {https://www.mdpi.com/2072-4292/12/18/2985},
ISSN = {2072-4292},
ABSTRACT = {Automatic road extraction from very-high-resolution remote sensing images has become a popular topic in a wide range of fields. Convolutional neural networks are often used for this purpose. However, many network models do not achieve satisfactory extraction results because of the elongated nature and varying sizes of roads in images. To improve the accuracy of road extraction, this paper proposes a deep learning model based on the structure of Deeplab v3. It incorporates squeeze-and-excitation (SE) module to apply weights to different feature channels, and performs multi-scale upsampling to preserve and fuse shallow and deep information. To solve the problems associated with unbalanced road samples in images, different loss functions and backbone network modules are tested in the model’s training process. Compared with cross entropy, dice loss can improve the performance of the model during training and prediction. The SE module is superior to ResNext and ResNet in improving the integrity of the extracted roads. Experimental results obtained using the Massachusetts Roads Dataset show that the proposed model (Nested SE-Deeplab) improves F1-Score by 2.4% and Intersection over Union by 2.0% compared with FC-DenseNet. The proposed model also achieves better segmentation accuracy in road extraction compared with other mainstream deep-learning models including Deeplab v3, SegNet, and UNet.},
DOI = {10.3390/rs12182985}
}

@INPROCEEDINGS{8628717,
  author={Varia, Neelanshi and Dokania, Akanksha and Senthilnath, J.},
  booktitle={2018 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={DeepExt: A Convolution Neural Network for Road Extraction using RGB images captured by UAV}, 
  year={2018},
  volume={},
  number={},
  pages={1890-1895},
  keywords={Roads;Feature extraction;Image segmentation;Generative adversarial networks;Data mining;Gallium nitride;Remote sensing;road extraction;convolutional neural nenvork;generative adversarial networks;semantic segmentation},
  doi={10.1109/SSCI.2018.8628717}}

@article{10.1117/1.JRS.12.016020,
author = {Ramesh Kestur and Shariq Farooq and Rameen Abdal and Emad Mehraj and Omkar Subbaramajois Narasipura and Meenavathi Mudigere},
title = {{UFCN: a fully convolutional neural network for road extraction in RGB imagery acquired by remote sensing from an unmanned aerial vehicle}},
volume = {12},
journal = {Journal of Applied Remote Sensing},
number = {1},
publisher = {SPIE},
pages = {016020},
keywords = {image segmentation, computer vision, remote sensing, deep learning, road extraction, fully convolutional neural networks, Roads, RGB color model, Unmanned aerial vehicles, Performance modeling, Data modeling, Image segmentation, Visual process modeling, Education and training, Matrices, Machine learning},
year = {2018},
doi = {10.1117/1.JRS.12.016020},
URL = {https://doi.org/10.1117/1.JRS.12.016020}
}

@ARTICLE{8447237,
  author={Henry, Corentin and Azimi, Seyed Majid and Merkle, Nina},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={Road Segmentation in SAR Satellite Images With Deep Fully Convolutional Neural Networks}, 
  year={2018},
  volume={15},
  number={12},
  pages={1867-1871},
  keywords={Roads;Image segmentation;Synthetic aperture radar;Satellites;Task analysis;Computer vision;Urban areas;Deep learning;high-resolution synthetic aperture radar (SAR) data;road extraction;SAR;semantic segmentation;TerraSAR-X},
  doi={10.1109/LGRS.2018.2864342}}

@InProceedings{10.1007/978-3-319-60663-7_18,
author="Panboonyuen, Teerapong
and Vateekul, Peerapon
and Jitkajornwanich, Kulsawasd
and Lawawirojwong, Siam",
editor="Meesad, Phayung
and Sodsee, Sunantha
and Unger, Herwig",
title="An Enhanced Deep Convolutional Encoder-Decoder Network for Road Segmentation on Aerial Imagery",
booktitle="Recent Advances in Information and Communication Technology 2017",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="191--201",
abstract="Object classification from images is among the many practical examples where deep learning algorithms have successfully been applied. In this paper, we present an improved deep convolutional encoder-decoder network (DCED) for segmenting road objects from aerial images. Several aspects of the proposed method are enhanced, incl. incorporation of ELU (exponential linear unit)---as opposed to ReLU (rectified linear unit) that typically outperforms ELU in most object classification cases; amplification of datasets by adding incrementally-rotated images with eight different angles in the training corpus (this eliminates the limitation that the number of training aerial images is usually limited), thus the number of training datasets is increased by eight times; and lastly, adoption of landscape metrics to further improve the overall quality of results by removing false road objects. The most recent DCED approach for object segmentation, namely SegNet, is used as one of the benchmarks in evaluating our method. The experiments were conducted on a well-known aerial imagery, Massachusetts roads dataset (Mass. Roads), which is publicly available. The results showed that our method outperforms all of the baselines in terms of precision, recall, and F1 scores.",
isbn="978-3-319-60663-7"
}

@article{Wang18062015,
author = {Jun Wang and Jingwei Song and Mingquan Chen and Zhi Yang},
title = {Road network extraction: a neural-dynamic framework based on deep learning and a finite state machine},
journal = {International Journal of Remote Sensing},
volume = {36},
number = {12},
pages = {3144--3169},
year = {2015},
publisher = {Taylor \& Francis},
doi = {10.1080/01431161.2015.1054049},


URL = { 
    
        https://doi.org/10.1080/01431161.2015.1054049
    
    

},
eprint = { 
    
        https://doi.org/10.1080/01431161.2015.1054049
    
    

}

}

@INPROCEEDINGS{8605652,
  author={Constantin, Alexandre and Ding, Jian-Jiun and Lee, Yih-Cherng},
  booktitle={2018 IEEE Asia Pacific Conference on Circuits and Systems (APCCAS)}, 
  title={Accurate Road Detection from Satellite Images Using Modified U-net}, 
  year={2018},
  volume={},
  number={},
  pages={423-426},
  keywords={Roads;Convolution;Training;Databases;Kernel;Satellites;Computer architecture;Deep learning;convolutional neural network (CNN);road extraction;satellite images},
  doi={10.1109/APCCAS.2018.8605652}}

  @ARTICLE{8309343,
  author={Zhang, Zhengxin and Liu, Qingjie and Wang, Yunhong},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={Road Extraction by Deep Residual U-Net}, 
  year={2018},
  volume={15},
  number={5},
  pages={749-753},
  keywords={Roads;Training;Neural networks;Remote sensing;Semantics;Image segmentation;Feature extraction;Convolutional neural network;deep residual U-Net;road extraction},
  doi={10.1109/LGRS.2018.2802944}}

  @ARTICLE{8447193,
  author={Hong, Zhaoli and Ming, Dongping and Zhou, Keqi and Guo, Ya and Lu, Tingting},
  journal={IEEE Access}, 
  title={Road Extraction From a High Spatial Resolution Remote Sensing Image Based on Richer Convolutional Features}, 
  year={2018},
  volume={6},
  number={},
  pages={46988-47000},
  keywords={Roads;Feature extraction;Data mining;Remote sensing;Training;Machine learning;Image edge detection;High spatial resolution remote sensing images;Richer convolutional features;road detection;road centerlines extraction and vectorization},
  doi={10.1109/ACCESS.2018.2867210}}

  @Article{rs11212499,
AUTHOR = {Xin, Jiang and Zhang, Xinchang and Zhang, Zhiqiang and Fang, Wu},
TITLE = {Road Extraction of High-Resolution Remote Sensing Images Derived from DenseUNet},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {21},
ARTICLE-NUMBER = {2499},
URL = {https://www.mdpi.com/2072-4292/11/21/2499},
ISSN = {2072-4292},
ABSTRACT = {Road network extraction is one of the significant assignments for disaster emergency response, intelligent transportation systems, and real-time updating road network. Road extraction base on high-resolution remote sensing images has become a hot topic. Presently, most of the researches are based on traditional machine learning algorithms, which are complex and computational because of impervious surfaces such as roads and buildings that are discernible in the images. Given the above problems, we propose a new method to extract the road network from remote sensing images using a DenseUNet model with few parameters and robust characteristics. DenseUNet consists of dense connection units and skips connections, which strengthens the fusion of different scales by connections at various network layers. The performance of the advanced method is validated on two datasets of high-resolution images by comparison with three classical semantic segmentation methods. The experimental results show that the method can be used for road extraction in complex scenes.},
DOI = {10.3390/rs11212499}
}

@article{Li03042019,
author = {Ye Li and Lele Xu and Jun Rao and Lili Guo and Zhen Yan and Shan Jin},
title = {A Y-Net deep learning method for road segmentation using high-resolution visible remote sensing images},
journal = {Remote Sensing Letters},
volume = {10},
number = {4},
pages = {381--390},
year = {2019},
publisher = {Taylor \& Francis},
doi = {10.1080/2150704X.2018.1557791},


URL = { 
    
        https://doi.org/10.1080/2150704X.2018.1557791
    
    

},
eprint = { 
    
        https://doi.org/10.1080/2150704X.2018.1557791
    
    

}}

@ARTICLE{7873262,
  author={Cheng, Guangliang and Wang, Ying and Xu, Shibiao and Wang, Hongzhen and Xiang, Shiming and Pan, Chunhong},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Automatic Road Detection and Centerline Extraction via Cascaded End-to-End Convolutional Neural Network}, 
  year={2017},
  volume={55},
  number={6},
  pages={3322-3337},
  keywords={Roads;Feature extraction;Remote sensing;Automobiles;Neural networks;Image segmentation;Data mining;Cascaded convolutional neural network (CasNet);end-to-end;road centerline extraction;road detection},
  doi={10.1109/TGRS.2017.2669341}}

  @ARTICLE{7876793,
  author={Wei, Yanan and Wang, Zulin and Xu, Mai},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={Road Structure Refined CNN for Road Extraction in Aerial Image}, 
  year={2017},
  volume={14},
  number={5},
  pages={709-713},
  keywords={Roads;Feature extraction;Training;Agriculture;Data mining;Semantics;Correlation;Convolutional neural network (CNN);machine learning;road extraction},
  doi={10.1109/LGRS.2017.2672734}}

@INPROCEEDINGS{8265456,
  author={Costea, Dragos and Marcu, Alina and Leordeanu, Marius and Slusanschi, Emil},
  booktitle={2017 IEEE International Conference on Computer Vision Workshops (ICCVW)}, 
  title={Creating Roadmaps in Aerial Images with Generative Adversarial Networks and Smoothing-Based Optimization}, 
  year={2017},
  volume={},
  number={},
  pages={2100-2109},
  keywords={Roads;Image segmentation;Optimization;Gallium nitride;Image edge detection;Generators},
  doi={10.1109/ICCVW.2017.246}}

@ARTICLE{8106771,
  author={Shi, Qian and Liu, Xiaoping and Li, Xia},
  journal={IEEE Access}, 
  title={Road Detection From Remote Sensing Images by Generative Adversarial Networks}, 
  year={2018},
  volume={6},
  number={},
  pages={25486-25494},
  keywords={Roads;Gallium nitride;Feature extraction;Image segmentation;Remote sensing;Training;Data models;Generative adversarial networks;end-to-end learning;road detection},
  doi={10.1109/ACCESS.2017.2773142}}

@misc{QuickBird2,
  title = {DigitalGlobe Completes QuickBird Satellite Orbit Raise},
  howpublished = {\url{https://web.archive.org/web/20140714153612/http://media.digitalglobe.com/manual-releases/DigitalGlobe-Completes-QuickBird-Satellite-Orbit-R}},
  note = {Accessed: 2025-11-14}
}

@misc{QuickBird2_wiki,
  title = {QuickBird Wiki article},
  howpublished = {\url{https://en.wikipedia.org/wiki/QuickBird}},
  note = {Accessed: 2025-11-14}
}